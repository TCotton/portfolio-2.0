{"authenticated": true, "stories": [{"friend_shares": [], "story_authors": "Chris Coyier", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://danielcwilson.com/blog/2015/07/animations-intro/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1442165570", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "532943:394f6c", "id": "https://css-tricks.com/?p=208124", "comment_count": 0, "story_title": "Let\u2019s talk about the Web Animations API", "guid_hash": "394f6c", "starred_timestamp": "1442312765", "share_count": 0, "friend_comments": [], "story_date": "2015-09-13 17:32:50", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "13 Sep 2015, 1:32pm", "story_tags": ["link"], "share_count_friends": 0, "image_urls": [], "story_feed_id": 532943, "long_parsed_date": "Sunday, September 13th, 2015 1:32pm", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Tuesday, September 15th, 2015 10:26am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p>Dan Wilson has an intro article followed by a 5-part series all about the Web Animations API. If you were unaware, <code>.animate()</code> is a native thing now. I think there is a ton of interesting things about the Web Animations API, like:</p>\n<ul>\n<li>Yet another great example of how a libraries pave the way, then browsers learn from that and get better. Then:<br />\n<blockquote><p>These libraries can then focus on providing newer features, and the cycle can continue.</p></blockquote>\n</li>\n<li>Under the browsers proverbial hood, the Web Animations API powers CSS animations as well.</li>\n<li>Will animation libraries, under their hoods, use this as part of the fallback stack? Or are they seeing equally good or better performance with <code>requestAnimationFrame</code> or whatever they are doing now? </li>\n<li>It's not every new web feature that has an <a href=\"https://github.com/web-animations/web-animations-js\">official polyfill</a>.</li>\n</ul>\n<p><a href=\"http://danielcwilson.com/blog/2015/07/animations-intro/\" title=\"Direct link to featured article\">Direct Link to Article</a> &#8212; <a href=\"https://css-tricks.com/lets-talk-about-the-web-animations-api/\">Permalink</a></p><hr />\n<p><small><a href=\"https://css-tricks.com/lets-talk-about-the-web-animations-api/\" rel=\"nofollow\">Let\u2019s talk about the Web Animations API</a> is a post from <a href=\"https://css-tricks.com\" rel=\"nofollow\">CSS-Tricks</a></small></p>", "starred": true}, {"friend_shares": [], "story_authors": "Philip Tellis", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://www.soasta.com/blog/options-web-performance-with-single-page-applications/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1439831971", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "2066719:049c75", "id": "http://www.soasta.com/?p=475164", "comment_count": 0, "story_title": "Solving the OPTIONS performance issue with single page apps", "guid_hash": "049c75", "starred_timestamp": "1439819626", "share_count": 0, "friend_comments": [], "story_date": "2015-08-17 17:19:31", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "17 Aug 2015, 1:19pm", "story_tags": ["devops blog", "tech topics", "ajax", "http", "options", "preflight", "xhr"], "share_count_friends": 0, "image_urls": ["https://farm1.staticflickr.com/41/75958718_46bad07b14_m.jpg", "http://www.soasta.com/wp-content/uploads/2015/08/Preflighted-XHR-2.png", "http://www.soasta.com/wp-content/uploads/2015/04/mpulse-banner6.jpg"], "story_feed_id": 2066719, "long_parsed_date": "Monday, August 17th, 2015 1:19pm", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Monday, August 17th, 2015 1:53pm", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p>Single-page applications are all the rage these days. <a href=\"https://angularjs.org/\">Various</a> <a href=\"http://emberjs.com/\">new</a> <a href=\"http://backbonejs.org/\">JavaScript</a> <a href=\"http://facebook.github.io/react/\">frameworks</a> make it very easy to write complex applications in JavaScript, with most of the MVC pattern running in the browser. This of course comes with its own challenges, and at SOASTA, we\u2019re always up for those.</p>\n<p>Back in May, my fellow <a href=\"https://github.com/lognormal/boomerang\">boomerang</a> developer <a href=\"https://twitter.com/nicj\">Nic Jansma</a> <a href=\"http://performancebeacon.com/angularjs-real-user-monitoring-single-page-applications/\">explained how we\u2019ve hacked boomerang to measure the performance of single-page applications</a>. Today, let\u2019s talk about another issue: the performance of SPAs when <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS\">CORS</a> comes into play.</p>\n<p><a href=\"https://twitter.com/mattetti\">Matt Aimonetti</a>, co-founder of <a href=\"https://splice.com/\">Splice</a>, tech entrepreneur, and regular conference speaker recently ran into this issue, and has agreed to co-author this post, sharing his experience.</p>\n<h1>But first, some history\u2026</h1>\n<p>Way back in the late 1990s, Microsoft introduced the XMLHttpRequest object to make background HTTP requests from JavaScript without disrupting the flow of a page; however, because no other browser (aka Netscape) supported it, it went largely unnoticed.</p>\n<p>On April 1, 2004, as part of an elaborate April Fool\u2019s joke that\u2019s ongoing to this day, Google released what by many is considered the first widely known single-page app (we called them Rich Internet Applications back then). They called it Gmail, and web developers everywhere started looking through the code to find out how they did it.</p>\n<div style=\"float: right; padding-left: 0.5em; text-align: center;\"><a href=\"https://www.flickr.com/photos/bluesmoon/75958718/in/album-1628984/\"><img alt=\"Pub Standards, Dec 2005\" height=\"160\" src=\"https://farm1.staticflickr.com/41/75958718_46bad07b14_m.jpg\" width=\"240\" />Pub Standards, Dec 2005</a></div>\n<p>In 2005, Jesse James Garrett coined the term AJAX to describe the communications method used by these apps, and standardistas everywhere decided to create best practices to avoid falling down the rabbit hole of unmaintainable code that failed accessibility standards we\u2019d worked so hard to create. Or as <a href=\"https://en.wikipedia.org/wiki/Thomas_Vander_Wal\">Thomas Vander Waal</a> put it:</p>\n<blockquote style=\"border-left: solid 3px #aaa; padding: 0.5em; font-style: italic;\"><p>\u201cIt must degrade well. It must still be accessible. It must be usable. If not, it is a cool useless piece of rubbish for some or many people.\u201d</p></blockquote>\n<p>With that, Jeremy Keith <a href=\"http://domscripting.com/blog/display/41\">introduced</a> us to <a href=\"http://domscripting.com/presentations/xtech2006/\">Hijax</a>.</p>\n<p>Now early on, browser developers realised they couldn\u2019t just allow you to make XHR calls anywhere, because that would allow attackers to steal third-party information in the background relying on a user\u2019s logged in cookies, so XHR was limited to the same-origin policy, i.e., you could only make an XHR call to a server that was on the same domain as the page you were making the call from. You could change document.domain to make this domain check slightly less restrictive, but it was still limited to a parent domain of the current page.</p>\n<h1>Enter CORS</h1>\n<p>This security model kinda worked, but we were also entering the age of Web APIs, where third parties wanted random websites to be able to pull data from their servers, potentially using the user\u2019s logged in cookies to get personalised information. But more importantly, websites wanted to be able to use their own APIs that were potentially served from a different domain (like their CDN). Things like <a href=\"http://tech.bluesmoon.info/2006/10/unintrusive-dynamic-script-nodes.html\">dynamic script nodes</a> and JSON-P worked, but they broke the security model, making it harder to protect these services from Cross-Site Request Forgeries.</p>\n<p>The web standards group stepped in to introduce the concept of Cross Origin Resource Sharing, or <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS\">CORS</a>, which states that a server can specify via the Access-Control-Allow-Origin header, which Origins its content is allowed to be shared with.</p>\n<h1>Preflighted requests</h1>\n<p>Unfortunately, every cool specification also comes with unexpected security considerations. For CORS, this is a preflighted request.</p>\n<p>According to <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS#Preflighted_requests\">MDN</a>,</p>\n<blockquote style=\"border-left: solid 3px #aaa; padding: 0.5em; font-style: italic;\"><p>In particular, a request is preflighted if:</p>\n<ul>\n<li>It uses methods <b>other</b> than GET, HEAD or POST. \u00a0Also, if POST is used to send request data with a Content-Type <b>other</b> than application/x-www-form-urlencoded, multipart/form-data, or text/plain, e.g. if the POST request sends an XML payload to the server using application/xml or text/xml, then the request <b>is</b> preflighted.</li>\n<li>It sets custom headers in the request (e.g. the request uses a header such as X-PINGOTHER)</li>\n</ul>\n</blockquote>\n<p>The idea is to ask the server for permission to send custom headers, and as <a href=\"https://remysharp.com/2011/04/21/getting-cors-working\">others</a> have <a href=\"https://www.sitepen.com/blog/2014/01/15/faq-cors-with-dojo/\">found</a>, the commonly used <code>X-Requested-With</code> HTTP header tends to trigger this.</p>\n<p><img alt=\"Flowchart for Preflighted XHR\" class=\"aligncenter size-full wp-image-475165\" height=\"407\" src=\"http://www.soasta.com/wp-content/uploads/2015/08/Preflighted-XHR-2.png\" width=\"768\" /></p>\n<p>At <a href=\"https://splice.com\">Splice</a>, we have a Go backend and we started out with a Rails frontend talking to our APIs. As time went by, the amount of JQuery code started to be hard to maintain and Rails rendering was becoming a bottleneck. We ported the frontend from Rails to Angular and everything seemed to be fine\u2026 until we started hearing complaints from our non-US users saying that parts of the website were slow for them. It turned out that these were the parts where we made many API calls to access user specific/signed/encrypted resources. Inspecting the network calls via a VPN connection, we noticed that main issue was latency.</p>\n<p>The latency between Sweden and California isn\u2019t great, but what\u2019s worse was that each API call had to wait on the preflight OPTIONS call before dispatching the actual request. Our API\u2019s response time is fast (sub 10ms), yet some users would see response times north of 500ms!</p>\n<p>This second HTTP OPTIONS request, doubles the latency for getting your data&#8230; and Real Users\u2122 hate latency.</p>\n<p>So, how do we get rid of this extra request?</p>\n<h1>X-Requested-With</h1>\n<p>To get to that, we need to understand why developers use the <code>X-Requested-With</code> header, which brings us all the way back to 2005 with all those best practices around Ajax. In order to use canonical URIs for all resources, we use the same URL for the full page request as well as the XHR request, and use the <code>X-Requested-With</code> header to distinguish between the requester.</p>\n<p>There are a couple of problems with this, though:</p>\n<ol>\n<li><code>X-Requested-With</code> is a custom header hoping to be a de-facto standard</li>\n<li>We\u2019re sending different responses for the same URL based on the type of requester rather than its advertised capabilities or the requested response format.</li>\n</ol>\n<p>This starts to smell a lot like the late \u201890s, when we served different HTML to Internet Explorer and Netscape.</p>\n<p>The solution for these problems is to use standard headers that correctly advertise capabilities or requested response format, and it turns out that the <a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616.txt\">HTTP spec</a> does have a standard header for just this purpose.</p>\n<h1>Other custom headers</h1>\n<p>In recent versions of Angular and JQuery, this header was actually removed by default unless explicitly added, so it wasn\u2019t an issue for Splice, but because we used to send this header (via JQuery), we wrongly assumed that preflight requests was unavoidable.</p>\n<p>We did, however have other custom headers that we used to report the version (git hash) of the JavaScript code making the request. These headers had the same effect, since they failed the custom headers check for the preflight.</p>\n<h2>The <code>Accept</code> header</h2>\n<p>The <code>Accept</code> header, described in section 14.1 of RFC 2616, allows the caller to specify the content types it is willing to receive. By default, the browser will include text/html as the <b>preferred</b> acceptable type. When making our XHR request, we could specify application/json, application/xml, text/csv or anything else as the <b>only</b> acceptable content type.</p>\n<p>Your server application can then look at the <code>Accept</code> header to decide whether to respond with the full HTML or with a JSON representation of the data or something else. The technical term for this is called <a href=\"https://en.wikipedia.org/wiki/Content_negotiation\">content negotiation</a>.</p>\n<p>Other implementations add a query string parameter to the URL specifying the requested content type or other parameters related to the client library like a version or a hash.</p>\n<h1>Caching</h1>\n<p>Responses to these requests can be cached if they have the appropriate cache-control headers. It\u2019s important to make sure that the server uses the Vary header to specify that the <code>Accept</code> header was used to generate negotiated content content, and therefore should be part of the cache key, both in the browser, as well as in intermediate proxies.</p>\n<h1>Summary</h1>\n<ol>\n<li>Cross-domain XMLHttpRequests work if the server supports the appropriate CORS headers.</li>\n<li>Adding custom headers or using a non-standard content-type forces the browser to issue a preflight OPTIONS request to determine if these are acceptable or not, and this effectively doubles the latency of fetching data.</li>\n<li>Avoid custom HTTP headers, and use standard headers like <code>Accept</code> for content negotiated responses instead.</li>\n<li>Use the Vary header to tell clients and intermediates that the <code>Accept</code> header is important for caching.</li>\n<li>It\u2019s important to learn from history so that we do not repeat old mistakes.</li>\n</ol>\n<h1>Notes</h1>\n<ul>\n<li><a href=\"https://en.wikipedia.org/wiki/Yui_(singer)\">YUI</a> does not add the <code>X-Requested-With</code> header when making XHRs.</li>\n<li><a href=\"https://en.wikipedia.org/wiki/Jake_Weary\">JQuery</a> does not add the <a href=\"https://github.com/jquery/jquery/blob/a117dd05f638a078c21dc57f19966f4ae81f98f0/src/ajax/xhr.js#L55\"><code>X-Requested-With</code> header for cross-domain XHRs</a></li>\n<li><a href=\"https://en.wikipedia.org/wiki/Dojo\">Dojo</a> does add the <code>X-Requested-With</code> header for all XHRs, and you need to <a href=\"https://www.sitepen.com/blog/2014/01/15/faq-cors-with-dojo/\">explicitly clear it</a></li>\n<li>As of version 1.1.1 (2012), <a href=\"https://github.com/angular/angular.js/blob/master/CHANGELOG.md#breaking-changes-52\">AngularJS no longer adds the <code>X-Requested-With</code> and X-XSFR-TOKEN</a>.</li>\n<li>Prototype.js does <a href=\"http://api.prototypejs.org/ajax/\">add the <code>X-Requested-With</code> header</a> along with other custom headers for XHRs and you need to <a href=\"http://kourge.net/node/131\">explicitly clear it</a>.</li>\n</ul>\n<h1>References</h1>\n<ul>\n<li>CORS at MDN: <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Access_control_CORS</a></li>\n<li>CORS by Nicholas Zakas: <a href=\"http://www.nczonline.net/blog/2010/05/25/cross-domain-ajax-with-cross-origin-resource-sharing/\">http://www.nczonline.net/blog/2010/05/25/cross-domain-ajax-with-cross-origin-resource-sharing/</a></li>\n<li>Browsers that support CORS: <a href=\"http://caniuse.com/#feat=cors\">http://caniuse.com/#feat=cors</a></li>\n<li>RFC 2616 (HTTP/1.1): <a href=\"http://www.w3.org/Protocols/rfc2616/rfc2616.txt\">http://www.w3.org/Protocols/rfc2616/rfc2616.txt</a></li>\n<li>Remy Sharp discussing this problem: <a href=\"https://remysharp.com/2011/04/21/getting-cors-working\">https://remysharp.com/2011/04/21/getting-cors-working</a></li>\n<li>Very good talk by <a href=\"https://twitter.com/jaffathecake\">@jaffathecake</a> about modern progressive enhancement: <a href=\"http://www.fivesimplesteps.com/products/modern-progressive-enhancement\">http://www.fivesimplesteps.com/products/modern-progressive-enhancement</a></li>\n</ul>\n<p><a href=\"https://www.soasta.com/mpulse/sign-up/\"><img alt=\"free website performance testing\" class=\"alignnone size-full wp-image-474193\" height=\"210\" src=\"http://www.soasta.com/wp-content/uploads/2015/04/mpulse-banner6.jpg\" width=\"800\" /></a></p>", "starred": true}, {"friend_shares": [], "story_authors": "Gergely Nemeth", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://blog.risingstack.com/fundamental-node-js-design-patterns/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1436862300", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "5738363:85cf73", "id": "2ae9d0de-6584-43d3-b4a0-b6c1c38e833a", "comment_count": 0, "story_title": "Fundamental Node.js Design Patterns", "guid_hash": "85cf73", "starred_timestamp": "1437021641", "share_count": 0, "friend_comments": [], "story_date": "2015-07-14 08:25:00", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "14 Jul 2015, 4:25am", "story_tags": ["tutorial", "nodejs", "design patterns"], "share_count_friends": 0, "image_urls": [], "story_feed_id": 5738363, "long_parsed_date": "Tuesday, July 14th, 2015 4:25am", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Thursday, July 16th, 2015 4:40am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<div><p>When talking about design patterns you may think of <strong>singletons</strong>, <strong>observers</strong> or <strong>factories</strong>. This article is not exclusively dedicated to them but deals with other common patterns as well, like <strong>dependency injection</strong> or <strong>middlewares</strong>.</p>\n\n<h1 id=\"whataredesignpatterns\">What are design patterns?</h1>\n\n<blockquote>\n  <p><em>A design pattern is a general, reusable solution to a commonly occurring problem.</em></p>\n</blockquote>\n\n<h3 id=\"singletons\">Singletons</h3>\n\n<p>The singleton patterns restrict the number of instantiations of a \"class\" to one. Creating singletons in Node.js is pretty straightforward, as <code>require</code> is there to help you.</p>\n\n<pre><code>//area.js\nvar PI = Math.PI;\n\nfunction circle (radius) {  \n  return radius * radius * PI;\n}\n\nmodule.exports.circle = circle;  \n</code></pre>\n\n<p>It does not matter how many times you will require this module in your application; it will only exist as a single instance.</p>\n\n<pre><code>var areaCalc = require('./area');\n\nconsole.log(areaCalc.circle(5));  \n</code></pre>\n\n<p>Because of this behaviour of <code>require</code>, singletons are probably the most common Node.js design patterns among the modules in NPM.</p>\n\n<h3 id=\"observers\">Observers</h3>\n\n<p>An object <strong>maintains a list of dependents/observers and notifies them</strong> automatically on state changes. To implement the observer pattern, <code>EventEmitter</code> comes to the rescue.</p>\n\n<pre><code>// MyFancyObservable.js\nvar util = require('util');  \nvar EventEmitter = require('events').EventEmitter;\n\nfunction MyFancyObservable() {  \n  EventEmitter.call(this);\n}\n\nutil.inherits(MyFancyObservable, EventEmitter);  \n</code></pre>\n\n<p>This is it; we just made an observable object! To make it useful, let's add some functionality to it.</p>\n\n<pre><code>MyFancyObservable.prototype.hello = function (name) {  \n  this.emit('hello', name);\n};\n</code></pre>\n\n<p>Great, now our observable can emit event - let's try it out!</p>\n\n<pre><code>var MyFancyObservable = require('MyFancyObservable');  \nvar observable = new MyFancyObservable();\n\nobservable.on('hello', function (name) {  \n  console.log(name);\n});\n\nobservable.hello('john');  \n</code></pre>\n\n<h3 id=\"factories\">Factories</h3>\n\n<p>The factory pattern is a creational pattern that doesn't require us to use a constructor but provides a <strong>generic interface for creating objects</strong>. This pattern can be really useful when the creation process is complex.</p>\n\n<pre><code>function MyClass (options) {  \n  this.options = options;\n}\n\nfunction create(options) {  \n  // modify the options here if you want\n  return new MyClass(options);\n}\n\nmodule.exports.create = create;  \n</code></pre>\n\n<p>Factories also make testing easier, as you can inject the modules dependencies using this pattern.</p>\n\n<h3 id=\"dependencyinjection\">Dependency Injection</h3>\n\n<blockquote>\n  <p>Dependency injection is a software design pattern in which one or more dependencies (or services) are injected, or passed by reference, into a dependent object.</p>\n</blockquote>\n\n<p>In this example, we are going to create a <code>UserModel</code> which gets a database dependency.</p>\n\n<pre><code>function userModel (options) {  \n  var db;\n\n  if (!options.db) {\n    throw new Error('Options.db is required');\n  }\n\n  db = options.db;\n\n  return {\n    create: function (done) {\n      db.query('INSERT ...', done);\n    }\n  }\n}\n\nmodule.exports = userModel;  \n</code></pre>\n\n<p>Now we can create an instance from it using:</p>\n\n<pre><code>var db = require('./db');\n\nvar userModel = require('User')({  \n  db: db\n});\n</code></pre>\n\n<p>Why is it helpful? It makes testing a lot easier - when you write your unit tests, you can easily inject a fake <code>db</code> instance into the model.</p>\n\n<h3 id=\"middlewarespipelines\">Middlewares / pipelines</h3>\n\n<p>Middlewares are a powerful yet simple concept: the <strong>output of one unit/function is the input for the next</strong>. If you ever used <a href=\"http://expressjs.com/\">Express</a> or <a href=\"http://koajs.com/\">Koa</a> then you already used this concept.</p>\n\n<p>It worths checking out how Koa does it: </p>\n\n<pre><code>app.use = function(fn){  \n  this.middleware.push(fn);\n  return this;\n};\n</code></pre>\n\n<p>So basically when you add a middleware it just gets pushed into a <code>middleware</code> array. So far so good, but what happens when a request hits the server?</p>\n\n<pre><code>var i = middleware.length;  \nwhile (i--) {  \n  next = middleware[i].call(this, next);\n}\n</code></pre>\n\n<p>No magic - your middlewares get called one after the other.</p>\n\n<h4 id=\"streams\">Streams</h4>\n\n<p>You can think of streams as special pipelines. They are better at processing bigger amounts of flowing data, even if they are bytes, not objects.</p>\n\n<pre><code>process.stdin.on('readable', function () {  \n    var buf = process.stdin.read(3);\n    console.dir(buf);\n    process.stdin.read(0);\n});\n</code></pre>\n\n<pre><code>$ (echo abc; sleep 1; echo def; sleep 1; echo ghi) | node consume2.js \n&lt;Buffer 61 62 63&gt;  \n&lt;Buffer 0a 64 65&gt;  \n&lt;Buffer 66 0a 67&gt;  \n&lt;Buffer 68 69 0a&gt;  \n</code></pre>\n\n<p><em>Example by <a href=\"https://twitter.com/substack\">substack</a></em></p>\n\n<p>To get a better understanding of streams check out substack's <a href=\"https://github.com/substack/stream-handbook\">Stream Handbook</a>.</p>\n\n<h3 id=\"furtherreading\">Further reading</h3>\n\n<ul>\n<li><a href=\"http://blog.risingstack.com/node-js-best-practices\">Node.js Best Practices</a>\n<ul><li>Callback convention, async code patterns, error handling and workflow tips.</li></ul></li>\n<li><a href=\"http://blog.risingstack.com/node-js-best-practices-part-2\">Node.js Best Practices Part 2</a>\n<ul><li>The next chapter, featuring pre-commit checks, JavaScript code style checker and configuration.</li></ul></li>\n</ul></div>", "starred": true}, {"friend_shares": [], "story_authors": "Dean McDonnell", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://www.nearform.com/nodecrunch/first-time-with-open-source/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1435158201", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "5914739:926e36", "id": "http://www.nearform.com/?p=2252", "comment_count": 0, "story_title": "Getting into open source for the first time", "guid_hash": "926e36", "starred_timestamp": "1436079236", "share_count": 0, "friend_comments": [], "story_date": "2015-06-24 15:03:21", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "24 Jun 2015, 11:03am", "story_tags": ["feature articles", "open source"], "share_count_friends": 0, "image_urls": ["http://www.nearform.com/wp-content/uploads/2015/06/github-pic-1.png", "http://www.nearform.com/wp-content/uploads/2015/06/Clone-a-local-copy.png", "http://www.nearform.com/wp-content/uploads/2015/06/Prepare-Pull-Request.png", "http://www.nearform.com/wp-content/uploads/2015/06/Having-your-code-viewed.png", "http://www.nearform.com/wp-content/uploads/2015/06/Handling-work-requests.png"], "story_feed_id": 5914739, "long_parsed_date": "Wednesday, June 24th, 2015 11:03am", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Sunday, July 5th, 2015 6:53am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p style=\"text-align: justify;\">Open source can be a thrilling hobby. My own contributions include work on projects like a <a href=\"https://github.com/rwaldron/johnny-five\" target=\"_blank\">IoT &amp; Robotics framework</a>, a <a href=\"https://github.com/nearform/nscale\" target=\"_blank\">Microservices deployment tool</a>, and a <a href=\"https://github.com/mcdonnelldean/atom-focus-white-syntax\" target=\"_blank\">self created theme</a> for GitHub\u2019s Atom.io text editor, to name a few. The breadth and variance of open source means that anyone with a text editor, terminal, and an internet connection can help build some really cool things with really cool people.</p>\n<p style=\"text-align: justify;\"><span id=\"more-2252\"></span></p>\n<h2><b>Tools of the trade</b></h2>\n<p style=\"text-align: justify;\">Specific tooling requirements vary depending on the particular language or environment you are working with. In most cases, along with any SDK\u2019s, having a <a href=\"https://github.com/join\" target=\"_blank\">GitHub account</a>, a <a href=\"https://atom.io/\" target=\"_blank\">robust text editor</a>, and <a href=\"https://git-scm.com/\" target=\"_blank\">Git</a> installed on your machine should be all you need.</p>\n<h2><b>Types of contribution</b></h2>\n<p style=\"text-align: justify;\">A good open source project has input from people of many different disciplines. Not all contributions need to be to the code proper, there are many different parts that come together to form a good project, working on code is only one of them.</p>\n<ul style=\"text-align: justify;\">\n<li>If you have design skills you could create and contribute assets for use in the project, it\u2019s social media accounts, or it\u2019s site.</li>\n</ul>\n<ul style=\"text-align: justify;\">\n<li>Front end skills can be put to use creating a project\u2019s home site, interactive samples, and tutorials.</li>\n</ul>\n<ul style=\"text-align: justify;\">\n<li>Anyone with a flair for writing can contribute to documentation. Every OSS project out there could benefit from more quality documentation.</li>\n</ul>\n<p style=\"text-align: justify;\">By not focusing solely on committing to the code portion of a project the work available greatly increases. Taking on work outside of your comfort zone is a great way to expand your skillset.</p>\n<h2><b>Selecting a project</b></h2>\n<p style=\"text-align: justify;\">A big issue for people new to open source is simply selecting a project to help out on in the first place. The advice I always give here is choose something that interests you. Below I\u2019ve listed some points to consider when making your decision:</p>\n<ul>\n<li style=\"text-align: justify;\"><i><b><i>Does the project want or need outside contribution? </i></b></i>Not every project wants or needs outside help. There are lots of projects that exist solely to scratch an itch, as experimentation, or even as a personal fork to play with ideas. In general if there is no contributing guide or no specific call to help it may be that the author isn\u2019t accepting contributions.</li>\n</ul>\n<ul style=\"text-align: justify;\">\n<li><b><i>Does the repo\u2019s purpose interest you?</i></b> Working on a project when you are not really all that interested never ends well. Open source contributions should be challenging but fun, if you are unhappily slogging away on a given project you may need to revalute your continued contribution.</li>\n</ul>\n<ul style=\"text-align: justify;\">\n<li><b><i><b><i>Are you happy with the project&#8217;s License and Policies? </i></b></i></b>Some projects have clear policies in relation to its License and Contributions, some don\u2019t. Before pulling the trigger and jumping in, it may be wise to do some research here. As an example, I rarely contribute to anything that has restricted licensing, including <a href=\"http://stackoverflow.com/questions/5603708/what-is-gpl-and-what-are-its-different-versions\" target=\"_blank\">GPL</a>. It\u2019s a personal choice, but one that needs to be made before you start contributing.</li>\n</ul>\n<ul style=\"text-align: justify;\">\n<li><b><i>Is the repository active?</i></b> Are there many outstanding issues and pull requests? Contributing to a dead repository is no fun and reviving one is no easy task.</li>\n</ul>\n<ul style=\"text-align: justify;\">\n<li><b><i>Is there work to be done for your skill level?</i></b> The best repositories to fork on are ones with work available you could tackle. Check the issues tab, run through the docs, look over tests. If there is something that needs to be done and you feel you can complete it, go for it!</li>\n</ul>\n<p style=\"text-align: justify;\">Keep an open mind about what projects you would like to work on and also the varying ways which you can help out. Sticking within your comfort zone is boring!</p>\n<h2 style=\"text-align: justify;\"><b>Contributing, step by step</b></h2>\n<p style=\"text-align: justify;\">Contributing to any repository follows a familiar pattern of steps, once you cycled through these steps a number of times on different repos the speed at which you can contribute increases.</p>\n<h3><b>Create a fork</b></h3>\n<p style=\"text-align: justify;\">Navigate to your chosen repository on GitHub. In the top right hand corner of the page, notice a small button named <b><i>fork</i></b>. Hit that to create a linked copy of the repository under your username.</p>\n<p><a href=\"http://www.nearform.com/wp-content/uploads/2015/06/github-pic-1.png\"><img alt=\"Getting into Open Source for the first time\" class=\"aligncenter size-full wp-image-2256\" height=\"410\" src=\"http://www.nearform.com/wp-content/uploads/2015/06/github-pic-1.png\" width=\"1600\" /></a></p>\n<h3><b>Clone a local copy</b></h3>\n<p style=\"text-align: justify;\">Navigate to your newly created fork, it will be named the same as it\u2019s parent. On the right hand side a clone link is presented. Hit the button to the right of the link to have it copied to your clipboard.</p>\n<p><a href=\"http://www.nearform.com/wp-content/uploads/2015/06/Clone-a-local-copy.png\"><img alt=\"Getting into Open Source for the first time \" class=\"aligncenter size-full wp-image-2258\" height=\"857\" src=\"http://www.nearform.com/wp-content/uploads/2015/06/Clone-a-local-copy.png\" width=\"1600\" /></a></p>\n<p style=\"text-align: justify;\">Next, on your machine select a location to clone this repository, navigate to this place using whatever console app you prefer and enter the command below, you only need to type <code>git clone</code>, the rest can be pasted from the clipboard.</p>\n<pre>git clone <a href=\"https://github.com/\" target=\"_blank\">https://github.com/</a>&lt;your-username&gt;/&lt;repo-name&gt;.git\n</pre>\n<p>A local copy of your repository will now reside in a folder named the same as the repo\u2019s name in your current working directory<strong>.</strong></p>\n<h3><b>Set up remote tracking</b></h3>\n<p style=\"text-align: justify;\">The local copy you just made needs to track both your remote repository as well as the original forked repository. By default, when cloning, a link is created back to your copy but not the original fork. Let\u2019s check what remote links are present:</p>\n<pre>git remote</pre>\n<p style=\"text-align: justify;\">You should have one remote named <i>origin </i>and may have one either named after the original author on GitHub or named <i>upstream. </i>By convention GitHub names the direct remote (in this case your copy) <i>origin</i> and the forked copy <i>upstream </i>but this is not a hard requirement, many people instead name their forks after the forked author.</p>\n<p style=\"text-align: justify;\">Since your repository is most likely missing the upstream remote, let&#8217;s add it. If we navigate to the original repository we can use the same copy button to copy the fork\u2019s URL:</p>\n<pre>git remote add upstream https://github.com/&lt;orginal-author&gt;/&lt;repor-name&gt;.git</pre>\n<p>Run, G<code>it remote</code> a second time to confirm the remote was correctly added, if it was you should see both origin and upstream listed.</p>\n<h3><b>Create a feature branch</b></h3>\n<p style=\"text-align: justify;\">In general, any changes made to a repository should be on a branch. All repositories will have a <i>master</i>branch which usually represents the latest clean version of the repositories content, unless otherwise stated by the repo owners this will be the branch you should base your feature branch off. Let\u2019s first ensure we are on the master branch:</p>\n<pre>git checkout master</pre>\n<p>Next, we are going to create a copy of master, as it is currently, on a new branch, which we can then modify without fear of breaking anything.</p>\n<pre>git branch -b name-of-branch</pre>\n<p style=\"text-align: justify;\">In general one branch equates to one <a href=\"https://help.github.com/articles/using-pull-requests/\" target=\"_blank\">PR</a>, keep branches focused to a single concept, if you need to add multiple features it may be better to create multiple branches, and later, multiple PR\u2019s, rather than sending a single gigantic PR to the upstream repository.</p>\n<h3 style=\"text-align: justify;\"><strong>Commit contributions</strong></h3>\n<p>A commit should be created every time it makes sense to do so, for instance, if you need to fix a bug, add a feature, and update tests, each should be done in a separate commit. Think of commits as natural checkpoints in your work.</p>\n<p style=\"text-align: justify;\">Before you commit, you must first \u201cstage\u201d your files. Staging is a way of grouping together a set of modified files to add to a commit. Only files specifically \u201cstaged\u201d can be committed. To stage all files for commit, run:</p>\n<pre>git add --all</pre>\n<p>If you need to be more specific with what you need to stage you can also stage a single file at a time using paths relative to the repository&#8217;s root directory:</p>\n<pre>git add /lib/my-file.js</pre>\n<p style=\"text-align: justify;\">You can also check the current status of the repository using G<code>it status</code>, which will tell you which files are modified, added, or deleted, as well as what is and isn\u2019t staged for commit.</p>\n<p>When you are happy with your staged changes it\u2019s time to create a commit and give it a message. \u00a0Simple commits can be done like so:</p>\n<pre>git commit -m \u201cFixed Bug\u201d</pre>\n<p style=\"text-align: justify;\">For bigger commits, Git supports multi-line messages. By leaving off the closing double quotation mark and pressing enter, Git will insert a new line which allows list style messages to be created as below. \u00a0Notice that once the second double quotation mark is added the next enter key press will complete the message and save the commit.</p>\n<pre style=\"text-align: justify;\">git commit - m \u201cAdded Feature\n- updated function to include callback\n- merged to and from logic\n- removed semicolons\u201d</pre>\n<p style=\"text-align: justify;\">If you need to construct more complex commit messages you can tell Git to open up a text editor when the <code>-m</code> flag is missing. Simply set the following in Git, Where EDITOR is the named command you would use in the terminal to open this editor.</p>\n<pre>git config --global core.editor \"EDITOR\"</pre>\n<p style=\"text-align: justify;\">From here it is simply a case of using G<code>it commit</code>. When you push enter Git will detect no message and open up your editor of choice. When you have completed the message save and exit from the editor, Git will pick up your changes and use them for the commit message.</p>\n<h3><b>Staying up to date</b></h3>\n<p>Your copy of the original repository will invariably become stale. To keep up to date is actually very simple. First we need to checkout the master branch:</p>\n<pre>git checkout master</pre>\n<p style=\"text-align: justify;\">Next we need to rebase our master branch so that it matches the upstream master branch. Rebase is too complex to detail here but essentially it rewrites your master branch so it matches the upstream master branch exactly<strong>.</strong></p>\n<pre>git pull --rebase upstream master</pre>\n<p>Finally because rebase is destructive and may rewrite your current master branch we need to tell Git to force update our remote fork:</p>\n<pre>git push -f origin master</pre>\n<p style=\"text-align: justify;\">Finally we need to check out our feature branch and rebase it with our local copy of master. This will yank any commits we have and place them at the end of the commit list. The importance of this will become apparent when we create our PR, the receiving repo will see our commits on top of theirs which makes merging much easier.</p>\n<pre>git checkout my-branch\ngit rebase master</pre>\n<h3><b>Prepare pull request</b></h3>\n<p style=\"text-align: justify;\">Pull requests are created on GitHub\u2019s website. Before creating a pull request we first need to push our branch up to our fork. It is good practice to first ensure your fork and branches are up to date, refer to the last section for how to do this. Once up to date we need to push our branch up to GitHub:</p>\n<pre>git push -f origin my-branch</pre>\n<p>To create a pull request, navigate to your fork and hit the pull request button on the right hand side of the repository explorer. Make sure you are on the right branch, by default, master will be selected but you can change to your branch using the branch drop down to the upper left of the pull request button.</p>\n<p style=\"text-align: justify;\"><img alt=\"Prepare Pull Request\" class=\"aligncenter size-full wp-image-2265\" height=\"514\" src=\"http://www.nearform.com/wp-content/uploads/2015/06/Prepare-Pull-Request.png\" width=\"1600\" /></p>\n<p style=\"text-align: justify;\">Before you do, take note of the detail to the left of the pull request button. It will tell you how many commits ahead you are (these will be included in the PR) and how many you are behind (a pull and rebase is required). In general, you should never submit a PR that is behind, if you do, you will inevitably be asked to update.</p>\n<h3><b>Having your code reviewed</b></h3>\n<p style=\"text-align: justify;\">Depending on the contributors you may be subjected to a pretty lengthy and sometimes intense code review. While these can seem disheartening, look at them as a learning experience. Sometimes it may be that your changes simply need some tidying up, other times the way you went about solving a problem doesn\u2019t fit with the repositories overall theme. Generally the advice or direction given during a code review is designed to improve the PR but let you have the experience of doing so, the language may be neutral or questioning but the intent is to let you make the PR better. Most contributors understand the importance of letting a person make any changes needed rather than doing it for them.</p>\n<p style=\"text-align: justify;\">A review should never be personal, it is the code, not you, that is up for review, with this in mind the following is never ok:</p>\n<ul>\n<li>Name calling, snideness, chiding, insults, or mocking.</li>\n<li>Comments and/or assumptions on your gender, sexuality, or person.</li>\n</ul>\n<p style=\"text-align: justify;\">If you feel a review has become personal depending on the circumstances you may be able to have a discussion with the repository owner to resolve any issues. In general, I find it is simply better to drop the PR and move on. Like any massive gathering of people there are good apples and bad apples.<strong><strong>\u00a0</strong></strong></p>\n<p style=\"text-align: justify;\">Fortunately, <a href=\"http://www.rust-lang.org/conduct.html\" target=\"_blank\">many</a>\u00a0<a href=\"https://github.com/nodejs/io.js/blob/master/CONTRIBUTING.md\" target=\"_blank\">Open Source</a>\u00a0<a href=\"http://hapijs.com/help#Code%20of%20Conduct\" target=\"_blank\">projects</a> now have express Code of Conduct or Contribution Guides to ensure that sound policies and procedures are in place, understood, and most importantly, enforced. A project with a solid Code of Conduct or Contributing Guide is usually a better place to spend your effort than one without.</p>\n<p><a href=\"http://www.nearform.com/wp-content/uploads/2015/06/Having-your-code-viewed.png\"><img alt=\"Getting into Open Source for the first time \" class=\"aligncenter size-full wp-image-2269\" height=\"1436\" src=\"http://www.nearform.com/wp-content/uploads/2015/06/Having-your-code-viewed.png\" width=\"1600\" /></a></p>\n<p style=\"text-align: justify;\">As your code is reviewed a timeline is created under the PR, each commit added and any notes from reviewers are all listed in the same place. This cycle may repeat a number of times, it\u2019s not unusual for multiple extra commits to be required before a PR is accepted.</p>\n<h3><b>Handling rework requests</b></h3>\n<p>Chances are, after a code review, you may need to add more commits to your pull request for any rework that needs to be completed.</p>\n<p><a href=\"http://www.nearform.com/wp-content/uploads/2015/06/Handling-work-requests.png\"><img alt=\"Handling work requests\" class=\"aligncenter size-full wp-image-2271\" height=\"1600\" src=\"http://www.nearform.com/wp-content/uploads/2015/06/Handling-work-requests.png\" width=\"1532\" /></a></p>\n<p style=\"text-align: justify;\">Luckily as long as you keep adding commits to the\u00a0same branch and then pushing them to your fork, the PR against that branch will be auto updated. If any of your changes out date the previous diff, GitHub will automatically hide any associated comments, this allows PR\u2019s to evolve without becoming overcrowded with older review messages.</p>\n<h3><b>Acceptance</b></h3>\n<p>Firstly,</p>\n<p><iframe allowfullscreen=\"allowfullscreen\" class=\"giphy-embed\" height=\"230\" src=\"http://giphy.com/embed/11uArCoB4fkRcQ\" width=\"480\"></iframe></p>\n<p style=\"text-align: justify;\">When your PR has been accepted you will need to pull the changes back into your fork, via your local repo. This is the exact same process as keeping your repository in sync, as listed above.</p>\n<pre>git checkout master\ngit pull --rebase upstream master\ngit push -f origin master</pre>\n<p>All that is left to do is clean up your local and remote branches by removing the now unneeded feature branch in both places.</p>\n<pre>git branch -D my_branch\ngit push origin --delete my_branch</pre>\n<p style=\"text-align: justify;\">From here, to kick the process off again simply checkout master, create a new branch, rinse and repeat. It is important to note that just because your changes are now in the main repository, it does not mean they have reached user yet. Generally a release is a bunching together of many PR\u2019s into a single public release.</p>\n<h2><b>Conclusion</b></h2>\n<p style=\"text-align: justify;\">Open source is both thrilling and mostly a joy to do. Using the information above it should be easy, with some practice, to get working on some cool and interesting projects. It\u2019s important to remember that everyone in open source started the same way.</p>\n<p style=\"text-align: justify;\">Let me know how you get on with your first foray into open source. I\u2019m always interested in how we can make it easier to help people get started. If you\u2019d like to know more about nearForm\u2019s approach to Open Source take a look <a href=\"http://www.nearform.com/about-us/\" target=\"_blank\">here</a> and you might even consider adding to our open source projects <a href=\"http://www.nearform.com/tool-nscale/\" target=\"_blank\">nScale</a> and <a href=\"http://www.nearform.com/seneca/\" target=\"_blank\">Seneca</a> too. Best of luck!</p>\n<p><em><span style=\"color: #ff0000;\">Want to work for nearForm? We\u2019re hiring.</span></em></p>\n<hr />\n<h3 style=\"text-align: center;\"><span style=\"color: #000000;\">Email\u00a0</span><span style=\"color: #ff0000;\"><a href=\"mailto:hello@nearform.com\" style=\"color: #1155cc;\" target=\"_blank\"><span style=\"color: #ce1515;\">hello@nearform.com</span></a></span></h3>\n<p style=\"text-align: center;\">Twitter\u00a0<a href=\"https://twitter.com/nearform\" target=\"_blank\">@nearform</a></p>\n<p style=\"text-align: center;\">Phone\u00a0<span style=\"color: #ce1515;\">+353-1-514 3545</span></p>\n<p style=\"text-align: center;\">Check out nearForm at\u00a0<a href=\"http://www.nearform.com/\" target=\"_blank\">www.nearform.com.</a></p>\n<hr />\n<p>The post <a href=\"http://www.nearform.com/nodecrunch/first-time-with-open-source/\" rel=\"nofollow\">Getting into open source for the first time</a> appeared first on <a href=\"http://www.nearform.com\" rel=\"nofollow\">nearForm</a>.</p>", "starred": true}, {"friend_shares": [], "story_authors": "Chris Coyier", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://www.kryogenix.org/code/browser/why-availability/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1435671014", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "532943:ebd987", "id": "https://css-tricks.com/?p=204409", "comment_count": 0, "story_title": "Why availability matters", "guid_hash": "ebd987", "starred_timestamp": "1436077292", "share_count": 0, "friend_comments": [], "story_date": "2015-06-30 13:30:14", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "30 Jun 2015, 9:30am", "story_tags": ["link"], "share_count_friends": 0, "image_urls": [], "story_feed_id": 532943, "long_parsed_date": "Tuesday, June 30th, 2015 9:30am", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Sunday, July 5th, 2015 6:21am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p>GIFs from Stuart Langridge demonstrating that a tiny percentage of visitors that can't view your site isn't just a static minority, it's a scattered minority. </p>\n<blockquote><p>It's not 1% of people who always can't see your site and 99% of people who always can. It's 1% of visits. Almost all the people who don't get your site correctly actually should have been able to.</p></blockquote>\n<p><a href=\"http://www.kryogenix.org/code/browser/why-availability/\" title=\"Direct link to featured article\">Direct Link to Article</a> &#8212; <a href=\"https://css-tricks.com/why-availability-matters/\">Permalink</a></p><hr />\n<p><small><a href=\"https://css-tricks.com/why-availability-matters/\" rel=\"nofollow\">Why availability matters</a> is a post from <a href=\"https://css-tricks.com\" rel=\"nofollow\">CSS-Tricks</a></small></p>", "starred": true}, {"friend_shares": [], "story_authors": "Robin Rendle", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "https://www.youtube.com/watch?v=miLnRHNj7nQ", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1435763485", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "532943:10e7ac", "id": "https://css-tricks.com/?p=204430", "comment_count": 0, "story_title": "HTTP 203: Progressive loading", "guid_hash": "10e7ac", "starred_timestamp": "1436076834", "share_count": 0, "friend_comments": [], "story_date": "2015-07-01 15:11:25", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "01 Jul 2015, 11:11am", "story_tags": ["link"], "share_count_friends": 0, "image_urls": [], "story_feed_id": 532943, "long_parsed_date": "Wednesday, July 1st, 2015 11:11am", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Sunday, July 5th, 2015 6:13am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p>The latest episode from <a href=\"https://developers.google.com/web/shows/http203/index?hl=en\">HTTP 203</a>, a series of talks about front-end development with <a href=\"https://twitter.com/aerotwist\">Paul Lewis</a> and <a href=\"https://twitter.com/jaffathecake\">Jake Archibald</a>, takes a look at progressively loading assets.</p>\n<p>Jake makes the comparison between websites and the way that video games will let users download and play the first level instead of forcing them to wait for the all the assets to finish downloading. What does your <em>level one</em> website look like?</p>\n<p><a href=\"https://www.youtube.com/watch?v=miLnRHNj7nQ\" title=\"Direct link to featured article\">Direct Link to Article</a> &#8212; <a href=\"https://css-tricks.com/http-203-progressive-loading/\">Permalink</a>&#8230;</p>\n<hr />\n<p><small><a href=\"https://css-tricks.com/http-203-progressive-loading/\" rel=\"nofollow\">HTTP 203: Progressive loading</a> is a post from <a href=\"https://css-tricks.com\" rel=\"nofollow\">CSS-Tricks</a></small></p>", "starred": true}, {"friend_shares": [], "story_authors": "Bart Jacobs", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://code.tutsplus.com/tutorials/swift-20-availability-checking--cms-24340", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1435949157", "share_user_ids": [109116], "user_id": 103195, "user_tags": [], "story_hash": "89:9376ce", "id": "tag:code.tutsplus.com,2005:PostPresenter/cms-24340", "comment_count": 0, "story_title": "Swift 2.0: Availability Checking", "guid_hash": "9376ce", "starred_timestamp": "1436074565", "share_count": 1, "friend_comments": [], "story_date": "2015-07-03 18:45:57", "share_count_public": 1, "friend_user_ids": [], "public_user_ids": [109116], "short_parsed_date": "03 Jul 2015, 2:45pm", "story_tags": [], "share_count_friends": 0, "image_urls": ["https://cms-assets.tutsplus.com/uploads%2Fusers%2F41%2Fposts%2F24340%2Fimage-1435861491333.jpg", "http://audio.tutsplus.com.feedsportal.com/c/35227/f/668806/s/24340/sc/4/mf.gif", "http://da.feedsportal.com/r/186529796139/u/407/f/668806/c/35227/s/24340/a2.img", "http://pi.feedsportal.com/r/186529796139/u/407/f/668806/c/35227/s/24340/a2t.img"], "story_feed_id": 89, "long_parsed_date": "Friday, July 3rd, 2015 2:45pm", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Sunday, July 5th, 2015 5:36am", "read_status": 1, "shared_by_public": [109116], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p>In this short tutorial, I\u2019d like to focus on Swift\u2019s brand new syntax for availability checking. If you\u2019ve done any amount of iOS or OS X development, then I\u2019m sure you know how tedious it can be to check if a particular API is available on the device your application is running on. In Swift 2, this has become much less of a pain for developers.</p>\n\n<h2>The Problem</h2>\n<p>Picture the following scenario. You\u2019re developing an iOS application that targets iOS 7 and up. During last year\u2019s WWDC, Apple introduced a new API for notification registration.</p>\n\n<pre class=\"brush: javascript noskimlinks noskimwords\">registerUserNotificationSettings(_:)\n</pre>\n\n<p>Does that mean that you need to raise your application\u2019s deployment target from iOS 7 to iOS 8? You could do that, but it would leave a significant portion of your application\u2019s user base in the cold, only to comply with Apple\u2019s new policy for local and remote notifications. Your users won\u2019t thank you for that.</p>\n\n<p>The alternative is to only use the new API on devices that run iOS 8 and up. That makes more sense. Right? The implementation would look something like this.</p>\n\n<pre class=\"brush: javascript noskimlinks noskimwords\">func application(application: UIApplication, didFinishLaunchingWithOptions launchOptions: [NSObject: AnyObject]?) -&gt; Bool {\n    if UIApplication.instancesRespondToSelector(\"registerUserNotificationSettings:\") {\n        let types = UIUserNotificationType.Alert | UIUserNotificationType.Sound | UIUserNotificationType.Badge\n        let settings = UIUserNotificationSettings(forTypes: types, categories: nil)\n        application.registerUserNotificationSettings(settings)\n    }\n    \n    return true\n}\n</pre>\n\n<p>This is a viable option, but it isn\u2019t witout risk. In this tutorial, I won\u2019t go into the details of what those risks involve, but I do want to emphasize that most developers think it\u2019s fine to use the above approach. The following example shows a variation of this approach, this time using Objective-C.</p>\n\n<pre class=\"brush: objc noskimlinks noskimwords\">if ([UIUserNotificationSettings class]) {\n    [application registerUserNotificationSettings:[UIUserNotificationSettings settingsForTypes:(UIUserNotificationTypeAlert | UIUserNotificationTypeSound | UIUserNotificationTypeBadge) categories:nil]];\n}\n</pre>\n\n<p>While both approaches will work in most situations, there are situations in which you\u2019ll run into problems. Some APIs, for example, start their lives as private APIs and are made public at a later stage. In that scenario, you may end up hitting private APIs on devices running an operating system in which those APIs aren\u2019t public yet. And I\u2019m sure you know what that means.</p>\n\n<h2>The Solution</h2>\n<p>Thanks to the work of the Swift team, the solution to our problem is simple and straightforward in Swift 2. Take a look at the following example. Note that the deployment target of the project is set to iOS 7, using <strong>Swift 2</strong> and <strong>Xcode 7</strong>.</p>\n\n<figure class=\"post_image\">\n<img alt=\"The compiler throws an error.\" src=\"https://cms-assets.tutsplus.com/uploads%2Fusers%2F41%2Fposts%2F24340%2Fimage-1435861491333.jpg\" />\n</figure>\n\n<p>In the example, we are using APIs that were introduced in iOS 8. Because the compiler knows that the deployment target of the project is set to iOS 7, it throws an error, telling us that the APIs we want to use are only available in iOS 8 and up. It knows this by inspecting the SDK for availability information. If you press <strong>Command</strong> and click the <code class=\"inline\">registerUserNotificationSettings(_:)</code> method, you should see something like this.</p>\n\n<pre class=\"brush: javascript noskimlinks noskimwords\">@available(iOS 8.0, *)\nfunc registerUserNotificationSettings(notificationSettings: UIUserNotificationSettings)\n</pre>\n\n<p>Fortunately, Xcode gives us a solution to resolve the issue. It suggests to use a version check to avoid that the APIs exclusive to iOS 8 and up are called if our users run the application on an older version of iOS.</p>\n\n<p>Note that this feature was introduced in Swift 2. The compiler won\u2019t throw an error if you\u2019re using Swift 1.2. The addition of the version check also makes the example easier to understand. Take a look at the updated example below in which we follow the advice Xcode has givesn us.</p>\n\n<pre class=\"brush: javascript noskimlinks noskimwords\">func application(application: UIApplication, didFinishLaunchingWithOptions launchOptions: [NSObject: AnyObject]?) -&gt; Bool {\n    if #available(iOS 8.0, *) {\n        let types = UIUserNotificationType([UIUserNotificationType.Alert, UIUserNotificationType.Sound, UIUserNotificationType.Badge])\n        let settings = UIUserNotificationSettings(forTypes: types, categories: nil)\n        application.registerUserNotificationSettings(settings)\n    }\n    \n    return true\n}\n</pre>\n\n<p>The syntax is clear and understandable. Using the availability syntax, we check if the application is running on a device with iOS 8 and up. If it isn\u2019t, the <code class=\"inline\">if</code> clause is skipped, otherwise the application calls the new API for notification registration.</p>\n\n<h2>Syntax</h2>\n<p>The syntax is straightforward. We start the availability condition with <code class=\"inline\">#available</code> and wrap the condition in parentheses. We can add as many platforms as necessary, separating the list of platforms with commas.</p>\n\n<pre class=\"brush: javascript noskimlinks noskimwords\">if #available(iOS 8.0, OSX 10.10, watchOS 2, *) {\n    ...\n}\n</pre>\n\n<p>Note that we end the list of platforms with an asterisk. This asterisk is required and indicates that the <code class=\"inline\">if</code> clause is executed on the minimum deployment target for any platform that aren\u2019t included in the list of platforms.</p>\n\n<p>As we saw earlier, we can use the <code class=\"inline\">@available</code> attribute to add availability information to functions, methods, and classes. In the following example, we tell the compiler that the <code class=\"inline\">useFancyNewAPI</code> should only be called on devices running iOS 9 and up.</p>\n\n<pre class=\"brush: javascript noskimlinks noskimwords\">@available(iOS 9.0, *)\nfunc useFancyNewAPI() {\n    ...\n}\n</pre>\n\n<h2>Conclusion</h2>\n<p>Keep in mind that the availability syntax is not an alternative for the two examples I showed you at the start of this tutorial. These examples are flawed and should only be used if you\u2019re using Objective-C or an earlier version of Swift.</p>\n\n<p>The availabilty syntax is yet another reason for migrating your Swift projects to Swift 2. It gets rid of error-prone solutions for checking API availability. The world looks a little bit friendlier with Swift 2. Doens\u2019t it?</p>\n<div class=\"mediafed_ad\"><img border=\"0\" height=\"1\" src=\"http://audio.tutsplus.com.feedsportal.com/c/35227/f/668806/s/24340/sc/4/mf.gif\" width=\"1\" /><a href=\"http://da.feedsportal.com/r/186529796139/u/407/f/668806/c/35227/s/24340/a2.htm\"><img border=\"0\" src=\"http://da.feedsportal.com/r/186529796139/u/407/f/668806/c/35227/s/24340/a2.img\" /></a><img border=\"0\" height=\"1\" src=\"http://pi.feedsportal.com/r/186529796139/u/407/f/668806/c/35227/s/24340/a2t.img\" width=\"1\" /></div>", "starred": true}, {"friend_shares": [], "story_authors": "David Rousset", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://feedproxy.google.com/~r/SitepointFeed/~3/PA6KYl7eSOY/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1430441159", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "5025883:7d91d5", "id": "http://www.sitepoint.com/?p=104513", "comment_count": 0, "story_title": "Enhance Your JavaScript Debugging with Cross-Browser Source Maps", "guid_hash": "7d91d5", "starred_timestamp": "1430449123", "share_count": 0, "friend_comments": [], "story_date": "2015-05-01 00:45:59", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "30 Apr 2015, 8:45pm", "story_tags": ["javascript", "raw javascript", "web dev @ microsoft", "adamr", "debugging", "mdn"], "share_count_friends": 0, "image_urls": ["http://dab1nmslvvntp.cloudfront.net/wp-content/uploads/2015/04/1430369902JSdebug01-GamePad-Test-Page.png", "http://dab1nmslvvntp.cloudfront.net/wp-content/uploads/2015/04/1430369905JSdebug02-Test-Page-Properties.png", "http://feeds.feedburner.com/~ff/SitepointFeed?d=yIl2AUoC8zA", "http://feeds.feedburner.com/~ff/SitepointFeed?d=qj6IDK7rITs", "http://feeds.feedburner.com/~ff/SitepointFeed?i=PA6KYl7eSOY:vtDVa0mVSpc:gIN9vFwOqvQ", "http://feeds.feedburner.com/~r/SitepointFeed/~4/PA6KYl7eSOY"], "story_feed_id": 5025883, "long_parsed_date": "Thursday, April 30th, 2015 8:45pm", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Friday, May 1st, 2015 2:58am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p><p>As a JavaScript developer, I\u2019m sure you\u2019ve already been falling into this scenario: something goes wrong with the production version of your code, and debugging it directly from the production server is a nightmare simply because it has been minified or has been compiled from another language such as <a href=\"http://www.typescriptlang.org/?WT.mc_id=13394-DEV-sitepoint-article18\">TypeScript</a> or CoffeeScript.</p>\n\n<p>The good news? The latest versions of browsers can help you solve this problem by using source map. In this tutorial, I\u2019ll show you how to find Source Maps in all of the browsers and get the most out of those few minutes you have to debug.</p>\n\n<h2 id=\"wait-what-are-source-maps\">Wait, what are Source Maps?</h2>\n\n<p>According to the great <a href=\"http://www.html5rocks.com/en/tutorials/developertools/sourcemaps/?WT.mc_id=13394-DEV-sitepoint-article18\">Introduction to JavaScript Source Maps</a> article, source map is \u201ca way to map a combined/minified file back to an unbuilt state. When you build for production, along with minifying and combining your JavaScript files, you generate a source map which holds information about your original files\u201d.</p>\n\n<p>Please don\u2019t hesitate to read <a href=\"http://www.html5rocks.com/profiles/#ryanseddon?WT.mc_id=13394-DEV-sitepoint-article18\">Ryan Seddon</a>\u2019s article first as it goes in great details on how source map works. You\u2019ll then learn that source map uses an intermediate file that does the matching between the production version of your code and its original development state. The format of this file is being described here: <a href=\"https://docs.google.com/document/d/1U1RGAehQwRypUTovF1KRlpiOFze0b-_2gc6fAH0KY0k/edit?hl=en_US&#38;pli=1&#38;pli=1?WT.mc_id=13394-DEV-sitepoint-article18\">Source Map Revision 3 Proposal</a></p>\n\n<p>Now to illustrate, I\u2019m going to share the way we\u2019re currently working while developing our WebGL Babylon.js open-source framework: <a href=\"http://www.babylonjs.com/\">http://www.babylonjs.com</a>. It\u2019s written in TypeScript. But the principles will remain the same if you\u2019re using plain JavaScript compressed/minified or other languages such as CoffeeScript.</p>\n\n<p>Let\u2019s now play with the source map magic directly in the browsers.</p>\n\n<h2 id=\"the-demo-page-were-going-to-use\">The demo page we\u2019re going to use</h2>\n\n<p>Recently, I\u2019ve been implementing the support of the <a href=\"https://www.youtube.com/watch?v=hQaKtGQ6qDo?WT.mc_id=13394-DEV-sitepoint-article18\">Gamepad API in our gaming engine</a>. Let\u2019s use its code for this tutorial.</p>\n\n<p>In this article, I\u2019m using the following browsers:</p>\n\n<ul>\n<li><strong>Internet Explorer 11</strong> , <a href=\"http://blogs.msdn.com/b/ie/archive/2014/08/13/august-updates-for-internet-explorer.aspx?WT.mc_id=13394-DEV-sitepoint-article18\">August update</a> (version 11.0.9600.17239) or even better, the developer channel version: <a href=\"http://devchannel.modern.ie/?utm_source=SitePoint&#38;utm_medium=article18&#38;utm_campaign=SitePoint\">devchannel.modern.ie</a> supporting the Gamepad API. A sidenote on IE: Microsoft is working on a new browser <a href=\"http://blogs.msdn.com/b/ie/archive/2015/02/26/a-break-from-the-past-the-birth-of-microsoft-s-new-web-rendering-engine.aspx\">Microsoft Edge</a> so be sure to check latest web standards support for it: <a href=\"http://status.modern.ie/?utm_source=SitePoint&#38;utm_medium=article18&#38;utm_campaign=SitePoint\">status.modern.IE</a>.</li>\n<li><strong>Chrome</strong> 38 developer channel (version 38.0.2125.8 dev-m) / <strong>Opera</strong> 23</li>\n<li><strong>Firefox</strong> 31 or Firefox 34 Nightly</li>\n</ul>\n\n<p>Navigate to this URL: <a href=\"http://david.blob.core.windows.net/babylonjs/gamepad/index.html\">http://david.blob.core.windows.net/babylonjs/gamepad/index.html</a> and you\u2019ll see this page:</p>\n\n<img alt=\"GamePad Test Page\" class=\"aligncenter size-full wp-image-104520\" height=\"190\" src=\"http://dab1nmslvvntp.cloudfront.net/wp-content/uploads/2015/04/1430369902JSdebug01-GamePad-Test-Page.png\" width=\"240\" />\n\n<p>Plug an Xbox 360 or Xbox One controller in the USB port of your machine. Press the A button to activate the gamepad and play with it:</p>\n\n<img alt=\"Test Page Properties\" class=\"aligncenter size-full wp-image-104521\" height=\"190\" src=\"http://dab1nmslvvntp.cloudfront.net/wp-content/uploads/2015/04/1430369905JSdebug02-Test-Page-Properties.png\" width=\"240\" />\n\n<p>But don\u2019t worry, you won\u2019t need a gamepad controller to follow this tutorial.</p>\n\n<p><strong>Note:</strong> The TypeScript compiler is automatically generating the source map for you. If you\u2019d like to generate a source map while generating your minified version of your code, I would recommend using Uglify JS 2: <a href=\"https://github.com/mishoo/UglifyJS2\">https://github.com/mishoo/UglifyJS2</a></p>\n\n<p>For this article, I even mixed both. I\u2019ve minified the JS generated by TypeScript and kept the source mapping intact using this command line:</p>\n\n<pre><code>uglifyjs testgamepad.js -o testgamepad.min.js --source-map testgamepad.min.js.map --in-source-map testgamepad.js.map\n</code></pre>\n\n<h2 id=\"how-to-debug-with-the-original-source-code\">How to debug with the original source code</h2>\n\n<h3 id=\"using-internet-explorer-11\">Using Internet Explorer 11</h3>\n\n<p>Once the gamepad test page has loaded, press F12 in IE11.</p>\n\n<p>You\u2019ll see that the HTML source is referencing 2 JavaScript files: <code>babylon.gamepads.js <strong></strong></code> at the beginning of the page &#38; <code>testgamepad.min.js</code> at the very end. The first file is coming from our framework on <a href=\"https://github.com/BabylonJS/Babylon.js/blob/master/Babylon/Tools/babylon.gamepads.js?WT.mc_id=13394-DEV-sitepoint-article18\">Github</a> and the second one a simple sample showing how to consume it.</p></p><p><em>Continue reading %<a href=\"http://www.sitepoint.com/enhance-your-javascript-debugging-with-cross-browser-source-maps/\" rel=\"nofollow\">Enhance Your JavaScript Debugging with Cross-Browser Source Maps</a>%</em></p><div class=\"feedflare\">\n<a href=\"http://feeds.feedburner.com/~ff/SitepointFeed?a=PA6KYl7eSOY:vtDVa0mVSpc:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/SitepointFeed?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/SitepointFeed?a=PA6KYl7eSOY:vtDVa0mVSpc:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/SitepointFeed?d=qj6IDK7rITs\" /></a> <a href=\"http://feeds.feedburner.com/~ff/SitepointFeed?a=PA6KYl7eSOY:vtDVa0mVSpc:gIN9vFwOqvQ\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/SitepointFeed?i=PA6KYl7eSOY:vtDVa0mVSpc:gIN9vFwOqvQ\" /></a>\n</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/SitepointFeed/~4/PA6KYl7eSOY\" width=\"1\" />", "starred": true}, {"friend_shares": [], "story_authors": "Elliot Bonneville", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://www.smashingmagazine.com/2015/04/08/web-scraping-with-nodejs/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1428498250", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "4809851:754624", "id": "http://www.smashingmagazine.com/?p=216707", "comment_count": 0, "story_title": "Web Scraping With Node.js", "guid_hash": "754624", "starred_timestamp": "1429963609", "share_count": 0, "friend_comments": [], "story_date": "2015-04-08 13:04:10", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "08 Apr 2015, 9:04am", "story_tags": ["coding", "javascript", "node.js"], "share_count_friends": 0, "image_urls": [], "story_feed_id": 4809851, "long_parsed_date": "Wednesday, April 8th, 2015 9:04am", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Saturday, April 25th, 2015 12:06pm", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p>Web scraping is the process of programmatically retrieving information from the Internet. As the volume of data on the web has increased, this practice has become increasingly widespread, and a number of powerful services have emerged to simplify it. Unfortunately, the majority of them are costly, limited or have other disadvantages. Instead of turning to one of these third-party resources, <strong>you can use Node.js to create a powerful web scraper</strong> that is both extremely versatile and completely free.</p>\n<p>In this article, I&#8217;ll be covering the following:</p>\n<ul>\n<li>two Node.js modules, Request and Cheerio, that simplify web scraping;</li>\n<li>an introductory application that fetches and displays some sample data;</li>\n<li>a more advanced application that finds keywords related to Google searches.</li>\n</ul>\n<p>Also, a few things worth noting before we go on: <strong>A basic understanding of Node.js is recommended for this article</strong>; so, if you haven\u2019t already, <a href=\"http://nodejs.org/\">check it out</a><sup class=\"po\" id=\"note-1\"><a href=\"http://www.smashingmagazine.com/feed/#1\">1</a></sup> before continuing. Also, web scraping may violate the terms of service for some websites, so just make sure you\u2019re in the clear there before doing any heavy scraping.</p>\n<h3 class=\"editorial\">Modules</h3>\n<p>To bring in the Node.js modules I mentioned earlier, we\u2019ll be using <a href=\"https://www.npmjs.com/\">NPM</a><sup class=\"po\" id=\"note-2\"><a href=\"http://www.smashingmagazine.com/feed/#2\">2</a></sup>, the Node Package Manager (if you\u2019ve heard of Bower, it\u2019s like that &mdash; except, you use NPM to install Bower). NPM is a package management utility that is automatically installed alongside Node.js to make the process of using modules as painless as possible. By default, NPM installs the modules in a folder named <code>node_modules</code> in the directory where you invoke it, so make sure to call it in your project folder.</p>\n<p>And without further ado, here are the modules we\u2019ll be using.</p>\n<h4>Request</h4>\n<p>While Node.js does provide simple methods of downloading data from the Internet via HTTP and HTTPS interfaces, you have to handle them separately, to say nothing of redirects and other issues that appear when you start working with web scraping. The <a href=\"https://github.com/request/request\">Request module</a><sup class=\"po\" id=\"note-3\"><a href=\"http://www.smashingmagazine.com/feed/#3\">3</a></sup> merges these methods, abstracts away the difficulties and presents you with a single unified interface for making requests. We\u2019ll use this module to download web pages directly into memory. To install it, run <code>npm install request</code> from your terminal in the directory where your main Node.js file will be located.</p>\n<h4>Cheerio</h4>\n<p><a href=\"https://github.com/cheeriojs/cheerio\">Cheerio</a><sup class=\"po\" id=\"note-4\"><a href=\"http://www.smashingmagazine.com/feed/#4\">4</a></sup> enables you to work with downloaded web data using the same syntax that jQuery employs. To quote the copy on its home page, \u201cCheerio is a fast, flexible and lean implementation of jQuery designed specifically for the server.\u201d Bringing in Cheerio enables us to focus on the data we download directly, rather than on parsing it. To install it, run <code>npm install cheerio</code> from your terminal in the directory where your main Node.js file will be located.</p>\n<h3>Implementation</h3>\n<p>The code below is a quick little application to nab the temperature from a weather website. I popped in my area code at the end of the URL we\u2019re downloading, but if you want to try it out, you can put yours in there (just make sure to install the two modules we\u2019re attempting to require first; you can learn how to do that via the links given for them above).</p>\n<pre><code class=\"language-javascript\">var request = require(\"request\"),\n\tcheerio = require(\"cheerio\"),\n\turl = \"http://www.wunderground.com/cgi-bin/findweather/getForecast?&amp;query=\" + 02888;\n\t\nrequest(url, function (error, response, body) {\n\tif (!error) {\n\t\tvar $ = cheerio.load(body),\n\t\t\ttemperature = $(\"[data-variable='temperature'] .wx-value\").html();\n\t\t\t\n\t\tconsole.log(\"It\u2019s \" + temperature + \" degrees Fahrenheit.\");\n\t} else {\n\t\tconsole.log(\"We\u2019ve encountered an error: \" + error);\n\t}\n});\n</code></pre>\n<p>So, what are we doing here? First, we\u2019re requiring our modules so that we can access them later on. Then, we\u2019re defining the URL we want to download in a variable.</p>\n<p>Then, we use the Request module to download the page at the URL specified above via the <code>request</code> function. We pass in the URL that we want to download and a callback that will handle the results of our request. When that data is returned, that callback is invoked and passed three variables: <code>error</code>, <code>response</code> and <code>body</code>. If Request encounters a problem downloading the web page and can\u2019t retrieve the data, it will pass a valid error object to the function, and the body variable will be null. Before we begin working with our data, we\u2019ll check that there aren\u2019t any errors; if there are, we\u2019ll just log them so we can see what went wrong.</p>\n<p>If all is well, we pass our data off to Cheerio. Then, we\u2019ll be able to handle the data like we would any other web page, using standard jQuery syntax. To find the data we want, we\u2019ll have to build a selector that grabs the element(s) we\u2019re interested in from the page. If you navigate to the URL I\u2019ve used for this example in your browser and start exploring the page with developer tools, you\u2019ll notice that the big green temperature element is the one I\u2019ve constructed a selector for. Finally, now that we\u2019ve got ahold of our element, it\u2019s a simple matter of grabbing that data and logging it to the console.</p>\n<p>We can take it plenty of places from here. I encourage you to play around, and I\u2019ve summarized the key steps for you below. They are as follows.</p>\n<h4>In Your Browser</h4>\n<ol>\n<li>Visit the page you want to scrape in your browser, being sure to record its URL.</li>\n<li>Find the element(s) you want data from, and figure out a jQuery selector for them.</li>\n</ol>\n<h4>In Your Code</h4>\n<ol>\n<li>Use request to download the page at your URL.</li>\n<li>Pass the returned data into Cheerio so you can get your jQuery-like interface.</li>\n<li>Use the selector you wrote earlier to scrape your data from the page.</li>\n</ol>\n<h3>Going Further: Data Mining</h3>\n<p>More advanced uses of web scraping can often be categorized as <a href=\"http://en.wikipedia.org/wiki/Data_mining\">data mining</a><sup class=\"po\" id=\"note-5\"><a href=\"http://www.smashingmagazine.com/feed/#5\">5</a></sup>, the process of downloading a lot of web pages and generating reports based on the data extracted from them. Node.js scales well for applications of this nature.</p>\n<p>I\u2019ve written a small data-mining app in Node.js, less than a hundred lines, to show how we\u2019d use the two libraries that I mentioned above in a more complicated implementation. The app finds the most popular terms associated with a specific Google search by analyzing the text of each of the pages linked to on the first page of Google results.</p>\n<p>There are three main phases in this app:</p>\n<ol>\n<li>Examine the Google search.</li>\n<li>Download all of the pages and parse out all the text on each page.</li>\n<li>Analyze the text and present the most popular words.</li>\n</ol>\n<p>We\u2019ll take a quick look at the code that\u2019s required to make each of these things happen &mdash; as you might guess, not a lot.</p>\n<h4>Downloading the Google Search</h4>\n<p>The first thing we\u2019ll need to do is find out which pages we\u2019re going to analyze. Because we\u2019re going to be looking at pages pulled from a Google search, we simply find the URL for the search we want, download it and parse the results to find the URLs we need.</p>\n<p>To download the page we use Request, like in the example above, and to parse it we\u2019ll use Cheerio again. Here\u2019s what the code looks like:</p>\n<pre><code class=\"language-javascript\">request(url, function (error, response, body) {\n\tif (error) {\n\t\tconsole.log(\u201cCouldn\u2019t get page because of error: \u201c + error);\n\t\treturn;\n\t}\n\t\n\t// load the body of the page into Cheerio so we can traverse the DOM\n\tvar $ = cheerio.load(body),\n\t\tlinks = $(\".r a\");\n\t\t\n\tlinks.each(function (i, link) {\n\t\t// get the href attribute of each link\n\t\tvar url = $(link).attr(\"href\");\n\t\t\n\t\t// strip out unnecessary junk\n\t\turl = url.replace(\"/url?q=\", \"\").split(\"&amp;\")[0];\n\t\t\n\t\tif (url.charAt(0) === \"/\") {\n\t\t\treturn;\n\t\t}\n\t\t\n\t\t// this link counts as a result, so increment results\n\t\ttotalResults++;\n</code></pre>\n<p>In this case, the URL variable we\u2019re passing in is a Google search for the term \u201cdata mining.\u201d</p>\n<p>As you can see, we first make a request to get the contents of the page. Then, we load the contents of the page into Cheerio so that we can query the DOM for the elements that hold the links to the pertinent results. Then, we loop through the links and strip out some extra URL parameters that Google inserts for its own usage &mdash; when we\u2019re downloading the pages with the Request module, we don\u2019t want any of those extra parameters.</p>\n<p>Finally, once we\u2019ve done all that, we make sure the URL doesn\u2019t start with a <code>/</code> &mdash; if so, it\u2019s an internal link to something else of Google\u2019s, and we don\u2019t want to try to download it, because either the URL is malformed for our purposes or, even if it isn\u2019t malformed, it wouldn\u2019t be relevant.</p>\n<h4>Pulling the Words From Each Page</h4>\n<p>Now that we have the URLs of our pages, we need to pull the words from each page. This step consists of doing much the same thing we did just above &mdash; only, in this case, the URL variable refers to the URL of the page that we found and processed in the loop above.</p>\n<pre><code class=\"language-javascript\">request(url, function (error, response, body) {\n\t// load the page into Cheerio\n\tvar $page = cheerio.load(body),\n\t\ttext = $page(\"body\").text();\n</code></pre>\n<p>Again, we use Request and Cheerio to download the page and get access to its DOM. Here, we use that access to get just the text from the page.</p>\n<p>Next, we\u2019ll need to clean up the text from the page &mdash; it\u2019ll have all sorts of garbage that we don\u2019t want on it, like a lot of extra white space, styling, occasionally even the odd bit of JSON data. This is what we\u2019ll need to do:</p>\n<ol>\n<li>Compress all white space to single spaces.</li>\n<li>Throw away any characters that aren\u2019t letters or spaces.</li>\n<li>Convert everything to lowercase.</li>\n</ol>\n<p>Once we\u2019ve done that, we can simply split our text on the spaces, and we\u2019re left with an array that contains all of the rendered words on the page. We can then loop through them and add them to our corpus.</p>\n<p>The code to do all that looks like this:</p>\n<pre><code class=\"language-javascript\">// Throw away extra white space and non-alphanumeric characters.\ntext = text.replace(/\\s+/g, \" \")\n\t     .replace(/[^a-zA-Z ]/g, \"\")\n\t     .toLowerCase();\n\n// Split on spaces for a list of all the words on that page and \n// loop through that list.\ntext.split(\" \").forEach(function (word) {\n\t// We don't want to include very short or long words because they're \n\t// probably bad data.\n\tif (word.length  20) {\n\t\treturn;\n\t}\n\t\t\t\t\n\tif (corpus[word]) {\n\t\t// If this word is already in our corpus, our collection\n\t\t// of terms, increase the count for appearances of that \n\t\t// word by one.\n\t\tcorpus[word]++;\n\t} else {\n\t\t// Otherwise, say that we've found one of that word so far.\n\t\tcorpus[word] = 1;\n\t}\n});\n</code></pre>\n<h4>Analyzing Our Words</h4>\n<p>Once we\u2019ve got all of our words in our corpus, we can loop through that and sort them by popularity. First, we\u2019ll need to stick them in an array, though, because the corpus is an object.</p>\n<pre><code class=\"language-javascript\">// stick all words in an array\nfor (prop in corpus) {\n\twords.push({\n\t\tword: prop,\n\t\tcount: corpus[prop]\n\t});\n}\n\t\n// sort array based on how often they occur\nwords.sort(function (a, b) {\n\treturn b.count - a.count;\n});\n</code></pre>\n<p>The result will be a sorted array representing exactly how often each word in it has been used on all of the websites from the first page of results of the Google search. Below is a sample set of results for the term \u201cdata mining.\u201d (Coincidentally, I used this list to generate the word cloud at the top of this article.)</p>\n<pre><code class=\"language-html\">[ { word: 'data', count: 981 },\n  { word: 'mining', count: 531 },\n  { word: 'that', count: 187 },\n  { word: 'analysis', count: 120 },\n  { word: 'information', count: 113 },\n  { word: 'from', count: 102 },\n  { word: 'this', count: 97 },\n  { word: 'with', count: 92 },\n  { word: 'software', count: 81 },\n  { word: 'knowledge', count: 79 },\n  { word: 'used', count: 78 },\n  { word: 'patterns', count: 72 },\n  { word: 'learning', count: 70 },\n  { word: 'example', count: 70 },\n  { word: 'which', count: 69 },\n  { word: 'more', count: 68 },\n  { word: 'discovery', count: 67 },\n  { word: 'such', count: 67 },\n  { word: 'techniques', count: 66 },\n  { word: 'process', count: 59 } ]\n</code></pre>\n<p>If you\u2019re interested in seeing the rest of the code, check out the <a href=\"https://gist.github.com/elliotbonneville/1bf694b8c83f358e0404\">fully commented source</a><sup class=\"po\" id=\"note-6\"><a href=\"http://www.smashingmagazine.com/feed/#6\">6</a></sup>.</p>\n<p>A good exercise going forward would be to take this application to the next level. You could optimize the text parsing, extend the search to multiple pages of Google results, even strip out common words that aren\u2019t really key terms (like \u201cthat\u201d and \u201cfrom\u201d). More bug handling could also be added to make the app even more robust &mdash; when you\u2019re mining data, you want as many layers of redundancy as you can reasonably afford. The variety of content that you\u2019ll be pulling in is such that inevitably you\u2019ll come across an unexpected piece of text that, if unhandled, would throw an error and promptly crash your application.</p>\n<h3>In Conclusion</h3>\n<p>As always, if you find anything related to web scraping with Node.js that you think is helpful or just have questions or thoughts you want to share, be sure to let us know via the comments below. Also, follow me <a href=\"https://twitter.com/bovenille\">on Twitter</a><sup class=\"po\" id=\"note-7\"><a href=\"http://www.smashingmagazine.com/feed/#7\">7</a></sup> and check out <a href=\"http://heyjavascript.com\">my blog</a><sup class=\"po\" id=\"note-8\"><a href=\"http://www.smashingmagazine.com/feed/#8\">8</a></sup> for more on Node.js, web scraping and JavaScript in general.</p>\n<p><em>(il, rb, al)</em></p>\n<h4 class=\"po\">Footnotes</h4><ol class=\"po\"><li id=\"#1\"><a href=\"http://www.smashingmagazine.com/feed/#note-1\">1 http://nodejs.org/</a></li><li id=\"#2\"><a href=\"http://www.smashingmagazine.com/feed/#note-2\">2 https://www.npmjs.com/</a></li><li id=\"#3\"><a href=\"http://www.smashingmagazine.com/feed/#note-3\">3 https://github.com/request/request</a></li><li id=\"#4\"><a href=\"http://www.smashingmagazine.com/feed/#note-4\">4 https://github.com/cheeriojs/cheerio</a></li><li id=\"#5\"><a href=\"http://www.smashingmagazine.com/feed/#note-5\">5 http://en.wikipedia.org/wiki/Data_mining</a></li><li id=\"#6\"><a href=\"http://www.smashingmagazine.com/feed/#note-6\">6 https://gist.github.com/elliotbonneville/1bf694b8c83f358e0404</a></li><li id=\"#7\"><a href=\"http://www.smashingmagazine.com/feed/#note-7\">7 https://twitter.com/bovenille</a></li><li id=\"#8\"><a href=\"http://www.smashingmagazine.com/feed/#note-8\">8 http://heyjavascript.com</a></li></ol><p>The post <a href=\"http://www.smashingmagazine.com/2015/04/08/web-scraping-with-nodejs/\" rel=\"nofollow\">Web Scraping With Node.js</a> appeared first on <a href=\"http://www.smashingmagazine.com\" rel=\"nofollow\">Smashing Magazine</a>.</p>", "starred": true}, {"friend_shares": [], "story_authors": "Dennis Gaebel", "intelligence": {"feed": 1, "tags": 0, "author": 0, "title": 0}, "shared_by_friends": [], "story_permalink": "http://feedproxy.google.com/~r/SitepointFeed/~3/M1Y8SRd1ac0/", "reply_count": 0, "comment_user_ids": [], "story_timestamp": "1427810434", "share_user_ids": [], "user_id": 103195, "user_tags": [], "story_hash": "5025883:6a2cbe", "id": "http://www.sitepoint.com/?p=102509", "comment_count": 0, "story_title": "Theming Form Elements with Sass", "guid_hash": "6a2cbe", "starred_timestamp": "1427962413", "share_count": 0, "friend_comments": [], "story_date": "2015-03-31 14:00:34", "share_count_public": 0, "friend_user_ids": [], "public_user_ids": [], "short_parsed_date": "31 Mar 2015, 10:00am", "story_tags": ["html & css", "sass", "form inputs", "forms", "sass", "sass theming", "stur", "theming"], "share_count_friends": 0, "image_urls": ["http://feeds.feedburner.com/~ff/SitepointFeed?d=yIl2AUoC8zA", "http://feeds.feedburner.com/~ff/SitepointFeed?d=qj6IDK7rITs", "http://feeds.feedburner.com/~ff/SitepointFeed?i=M1Y8SRd1ac0:Z1SMJB--R68:gIN9vFwOqvQ", "http://feeds.feedburner.com/~r/SitepointFeed/~4/M1Y8SRd1ac0"], "story_feed_id": 5025883, "long_parsed_date": "Tuesday, March 31st, 2015 10:00am", "comment_count_friends": 0, "public_comments": [], "commented_by_friends": [], "starred_date": "Thursday, April 2nd, 2015 8:13am", "read_status": 1, "shared_by_public": [], "comment_count_public": 0, "commented_by_public": [], "story_content": "<p><p>Form inputs without a doubt encompass a sizable portion of the Web. Since form controls can and will be encountered by users daily, it only seems fitting to lend our attention to a few suspects by furnishing each one with Sass' strength to help us theme our project's input's swiftly.</p>\n\n<h2>Placeholders</h2>\n\n<p>A <a href=\"http://caniuse.com/#feat=input-placeholder\">placeholder</a> is a hint to users as to what information can be entered within the corresponding control. It applies when the value of the <code>type</code> attribute is set as <code>text</code>, <code>search</code>, <code>tel</code>, <code>url</code> or <code>email</code>; otherwise it's ignored. Unfortunately to style the placeholder requires the appropriate vendor prefixes associated with each pseudo required so authors can deliver coverage across the major browser vendors such as IE, Firefox, Safari, Chrome and Opera.</p>\n\n<h3>A Mixin Helper</h3>\n\n<p>This placeholder <code>@mixin</code> can be used within a variety of contexts such as applying it alone or combined with a selector of your choosing. I've also taken the liberty of constructing a <a href=\"http://www.sitepoint.com/using-sass-maps\">Sass map</a> that contains all the properties you're allowed to style.</p>\n\n<p><strong>index.html</strong></p>\n\n[code language=\"html\"]\n<label for=\"username\">Name</label>\n<input id=\"username\" name=\"username\" type=\"text\" />\n[/code]\n\n<p><strong>_placeholder-mixin.scss</strong></p>\n\n<p>The <a href=\"http://www.alwaystwisted.com/articles/2014-03-08-using-sass-33s-at-root-for-piece-of-mind\"><code>@at-root</code></a> directive used by these mixins works by switching context where the nested call in your Sass is placed and pulls the declaration to the top level of the selector chain.</p></p><p><em>Continue reading %<a href=\"http://www.sitepoint.com/theming-form-elements-sass/\" rel=\"nofollow\">Theming Form Elements with Sass</a>%</em></p><div class=\"feedflare\">\n<a href=\"http://feeds.feedburner.com/~ff/SitepointFeed?a=M1Y8SRd1ac0:Z1SMJB--R68:yIl2AUoC8zA\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/SitepointFeed?d=yIl2AUoC8zA\" /></a> <a href=\"http://feeds.feedburner.com/~ff/SitepointFeed?a=M1Y8SRd1ac0:Z1SMJB--R68:qj6IDK7rITs\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/SitepointFeed?d=qj6IDK7rITs\" /></a> <a href=\"http://feeds.feedburner.com/~ff/SitepointFeed?a=M1Y8SRd1ac0:Z1SMJB--R68:gIN9vFwOqvQ\"><img border=\"0\" src=\"http://feeds.feedburner.com/~ff/SitepointFeed?i=M1Y8SRd1ac0:Z1SMJB--R68:gIN9vFwOqvQ\" /></a>\n</div><img alt=\"\" height=\"1\" src=\"http://feeds.feedburner.com/~r/SitepointFeed/~4/M1Y8SRd1ac0\" width=\"1\" />", "starred": true}], "result": "ok", "user_id": 103195, "feeds": {"5025883": {"subs": 649, "favicon_url": "https://s3.amazonaws.com/icons.newsblur.com/5025883.png", "is_push": true, "id": 5025883, "feed_address": "http://feeds.feedburner.com/SitepointFeed", "feed_link": "http://www.sitepoint.com", "updated_seconds_ago": 730, "favicon_fetching": false, "favicon_border": "bb7832", "last_story_date": "2015-12-03 20:00:14", "not_yet_fetched": false, "updated": "12 minutes", "average_stories_per_month": 116, "s3_icon": true, "feed_title": "SitePoint", "favicon_fade": "ffc466", "last_story_seconds_ago": 1651, "favicon_color": "faa143", "stories_last_month": 132, "fetched_once": true, "favicon_text_color": "white", "num_subscribers": 649, "s3_page": false, "min_to_decay": 72, "search_indexed": true}}, "message": null, "user_profiles": [{"username": "alvinashcraft", "feed_address": "http://www.newsblur.com/social/rss/109116/alvinashcraft", "user_id": 109116, "feed_link": "http://alvinashcraft.newsblur.com/", "num_subscribers": 19, "feed_title": "alvinashcraft's blurblog", "private": false, "protected": false, "location": "West Grove, PA", "large_photo_url": "https://www.gravatar.com/avatar/19ac6a9d902c1d6ae33f41405e47b385", "id": "social:109116", "photo_url": "https://www.gravatar.com/avatar/19ac6a9d902c1d6ae33f41405e47b385"}]}